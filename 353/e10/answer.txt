Question 1
    (1) 0m4.081s
    (2) 0m9.167s
    (3) 0m7.216s
    (4) 0m5.917s

Question 2
    Most of the time spend is reading the file, if you find ways to reduce
    the amount of times it reads the file the time goes down.

    it looks like reading the file takes about ~1.5 seconds, but the difference
    between starting spark and doing nothing, and reading the file once with caching
    is ~2 so calculating takes very little time.

Question 3
    I used cache() right before I used the dataframe-pages back to back without rewriting to it
    So up to line 45 within the Main() if I was smarter I think that could have been all one line
    because it is all in serial, but lines 50 and 52 each use pages and can run in parrallel
    so sparks lazyness would have thrown out pages after line 50 and had to redo for line 52. 
    